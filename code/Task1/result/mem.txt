Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task 1\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   123    734.5 MiB    734.5 MiB           1   @profile(stream=open("result/mem.txt", "a", encoding="UTF-8"))
   124                                         def test(args: argparse.Namespace):
   125                                             # load the data from csv file.
   126    734.5 MiB      0.0 MiB           1       print("Loading data.")
   127    735.8 MiB      1.4 MiB           1       train_x, train_y = loadData(os.path.join(args.data_dir, "train.csv"), True)
   128    736.6 MiB      0.8 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"))
   129                                         
   130                                             # Preprocessing
   131    736.6 MiB      0.0 MiB           1       print("Preprocessing")
   132    739.0 MiB      2.4 MiB           1       train_x = preprocess(train_x, args)
   133    740.0 MiB      1.0 MiB           1       test_x = preprocess(test_x, args)
   134                                         
   135                                             # Training and testing.
   136    740.0 MiB      0.0 MiB           1       print("Training and testing.")
   137    740.0 MiB      0.0 MiB           1       score = 0.0
   138                                         
   139    740.0 MiB      0.0 MiB           1       model = getModel(args)
   140    741.3 MiB      1.3 MiB           1       model.fit(train_x, train_y)
   141    741.3 MiB      0.0 MiB           1       pred_y = model.predict(train_x)
   142                                         
   143    741.3 MiB     -0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   144                                         
   145    741.3 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   146    741.3 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   147                                         
   148    741.6 MiB      0.3 MiB           1       pred_y = model.predict(test_x)
   149                                         
   150    741.6 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   151    741.6 MiB      0.0 MiB           1           print("StudentID,label", file=fp)
   152    741.7 MiB      0.0 MiB        2908           for i in range(len(test_id)):
   153    741.7 MiB      0.1 MiB        2907               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   154                                         
   155    741.7 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task 1\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   123    493.5 MiB    493.5 MiB           1   @profile(stream=open("result/mem.txt", "a", encoding="UTF-8"))
   124                                         def test(args: argparse.Namespace):
   125                                             # load the data from csv file.
   126    493.5 MiB      0.0 MiB           1       print("Loading data.")
   127    493.6 MiB      0.0 MiB           1       train_x, train_y = loadData(os.path.join(args.data_dir, "train.csv"), True)
   128    494.1 MiB      0.5 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"))
   129                                         
   130                                             # Preprocessing
   131    494.1 MiB      0.0 MiB           1       print("Preprocessing")
   132    494.9 MiB      0.9 MiB           1       train_x = preprocess(train_x, args)
   133    494.9 MiB      0.0 MiB           1       test_x = preprocess(test_x, args)
   134                                         
   135                                             # Training and testing.
   136    494.9 MiB      0.0 MiB           1       print("Training and testing.")
   137    494.9 MiB      0.0 MiB           1       score = 0.0
   138                                         
   139    494.9 MiB      0.0 MiB           1       model = getModel(args)
   140    495.6 MiB      0.7 MiB           1       model.fit(train_x, train_y)
   141    497.4 MiB      1.7 MiB           1       pred_y = model.predict(train_x)
   142                                         
   143    497.4 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   144                                         
   145    497.4 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   146    497.4 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   147                                         
   148    497.4 MiB      0.1 MiB           1       pred_y = model.predict(test_x)
   149                                         
   150    497.4 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   151    497.4 MiB      0.0 MiB           1           print("StudentID,label", file=fp)
   152    497.5 MiB      0.0 MiB        2908           for i in range(len(test_id)):
   153    497.5 MiB      0.0 MiB        2907               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   154                                         
   155    497.5 MiB      0.0 MiB           1       return None


