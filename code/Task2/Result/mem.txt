Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task2\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   109    553.3 MiB    553.3 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   110                                         def test(args: argparse.Namespace):
   111                                             # load the data from csv file.
   112    553.3 MiB      0.0 MiB           1       print("Loading data.")
   113    588.7 MiB     35.5 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   114    598.1 MiB      9.4 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   115                                         
   116                                             # Preprocessing
   117    598.1 MiB      0.0 MiB           1       print("Preprocessing")
   118    603.6 MiB      5.5 MiB           1       imputer = KNNImputer(n_neighbors=5).fit(train_x)
   119    578.7 MiB    -25.0 MiB           1       train_x = imputer.transform(train_x)
   120    571.8 MiB     -6.8 MiB           1       test_x = imputer.transform(test_x)
   121    571.8 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   122    571.8 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   123                                         
   124                                             # Training and testing.
   125    571.8 MiB      0.0 MiB           1       print("Training and testing.")
   126    571.8 MiB      0.0 MiB           1       score = 0.0
   127                                         
   128    571.8 MiB      0.0 MiB           1       model = getModel(args)
   129    586.8 MiB     15.0 MiB           1       model.fit(train_x, train_y)
   130    581.5 MiB     -5.3 MiB           1       pred_y = model.predict(train_x)
   131                                         
   132    582.0 MiB      0.5 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   133                                         
   134    582.0 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   135    582.0 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   136                                         
   137    585.8 MiB      3.7 MiB           1       pred_y = model.predict(test_x)
   138                                         
   139    585.8 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   140    585.8 MiB      0.0 MiB           1           print("id,label", file=fp)
   141    585.8 MiB      0.0 MiB       10001           for i in range(len(test_id)):
   142    585.8 MiB      0.0 MiB       10000               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   143                                         
   144    585.8 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task2\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   109    755.6 MiB    755.6 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   110                                         def test(args: argparse.Namespace):
   111                                             # load the data from csv file.
   112    755.6 MiB      0.0 MiB           1       print("Loading data.")
   113    800.2 MiB     44.5 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   114    809.7 MiB      9.5 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   115                                         
   116                                             # Preprocessing
   117    809.7 MiB      0.0 MiB           1       print("Preprocessing")
   118    815.2 MiB      5.5 MiB           1       imputer = KNNImputer(n_neighbors=5).fit(train_x)
   119    787.5 MiB    -27.7 MiB           1       train_x = imputer.transform(train_x)
   120    779.7 MiB     -7.8 MiB           1       test_x = imputer.transform(test_x)
   121    779.7 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   122    779.7 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   123                                         
   124                                             # Training and testing.
   125    779.7 MiB      0.0 MiB           1       print("Training and testing.")
   126    779.7 MiB      0.0 MiB           1       score = 0.0
   127                                         
   128    779.7 MiB      0.0 MiB           1       model = getModel(args)
   129    780.1 MiB      0.4 MiB           1       model.fit(train_x, train_y)
   130    780.1 MiB      0.0 MiB           1       pred_y = model.predict(train_x)
   131                                         
   132    780.1 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   133                                         
   134    780.1 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   135    780.1 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   136                                         
   137    781.5 MiB      1.4 MiB           1       pred_y = model.predict(test_x)
   138                                         
   139    781.5 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   140    781.5 MiB      0.0 MiB           1           print("id,label", file=fp)
   141    781.5 MiB     -2.1 MiB       10001           for i in range(len(test_id)):
   142    781.5 MiB     -2.0 MiB       10000               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   143                                         
   144    781.5 MiB      0.0 MiB           1       return None


