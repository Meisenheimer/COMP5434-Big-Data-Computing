Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    796.8 MiB    796.8 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    796.8 MiB      0.0 MiB           1       print("Loading data.")
   106    847.2 MiB     50.4 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    881.6 MiB     34.4 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    881.6 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    881.6 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    881.6 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    881.6 MiB      0.0 MiB           1       print("Training and testing.")
   117    881.6 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    881.6 MiB      0.0 MiB           1       model = getModel(args)
   120    928.4 MiB     46.8 MiB           1       model.fit(train_x, train_y)
   121    909.2 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    909.2 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    909.2 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    909.2 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    929.2 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    929.2 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    929.2 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    929.3 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    929.3 MiB      0.1 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    929.3 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    797.0 MiB    797.0 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    797.0 MiB      0.0 MiB           1       print("Loading data.")
   106    848.3 MiB     51.3 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    865.5 MiB     17.2 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    865.5 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    865.5 MiB     -0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    865.5 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    865.5 MiB      0.0 MiB           1       print("Training and testing.")
   117    865.5 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    865.5 MiB      0.0 MiB           1       model = getModel(args)
   120    915.1 MiB     49.6 MiB           1       model.fit(train_x, train_y)
   121    895.9 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    895.9 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    895.9 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    895.9 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    915.9 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    915.9 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    915.9 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    916.2 MiB     -0.2 MiB       89934           for i in range(len(test_id)):
   133    916.2 MiB     -0.1 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    916.2 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    797.5 MiB    797.5 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    797.5 MiB      0.0 MiB           1       print("Loading data.")
   106    835.4 MiB     37.8 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    863.3 MiB     28.0 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    863.3 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    863.3 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    863.3 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    863.3 MiB      0.0 MiB           1       print("Training and testing.")
   117    863.3 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    863.3 MiB      0.0 MiB           1       model = getModel(args)
   120    897.2 MiB     33.9 MiB           1       model.fit(train_x, train_y)
   121    884.4 MiB    -12.9 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    884.4 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    884.4 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    884.4 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    898.9 MiB     14.5 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    898.9 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    898.9 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    899.1 MiB     -4.2 MiB       89934           for i in range(len(test_id)):
   133    899.1 MiB     -4.1 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    899.1 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    797.5 MiB    797.5 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    797.5 MiB      0.0 MiB           1       print("Loading data.")
   106    848.7 MiB     51.2 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    881.4 MiB     32.7 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    881.4 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    881.4 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    881.4 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    881.4 MiB      0.0 MiB           1       print("Training and testing.")
   117    881.4 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    881.4 MiB      0.0 MiB           1       model = getModel(args)
   120    928.2 MiB     46.8 MiB           1       model.fit(train_x, train_y)
   121    908.9 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    908.9 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    908.9 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    908.9 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    928.9 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    929.0 MiB      0.1 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    929.0 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    929.1 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    929.1 MiB      0.1 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    929.1 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    801.2 MiB    801.2 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    801.2 MiB      0.0 MiB           1       print("Loading data.")
   106    839.8 MiB     38.6 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    866.4 MiB     26.6 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    866.4 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    866.4 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    866.4 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    866.4 MiB      0.0 MiB           1       print("Training and testing.")
   117    866.4 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    866.4 MiB      0.0 MiB           1       model = getModel(args)
   120    900.2 MiB     33.8 MiB           1       model.fit(train_x, train_y)
   121    887.3 MiB    -12.9 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    887.3 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    887.3 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    887.3 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    901.8 MiB     14.5 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    901.8 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    901.8 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    902.3 MiB      0.2 MiB       89934           for i in range(len(test_id)):
   133    902.3 MiB      0.3 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    902.3 MiB      0.0 MiB           1       return None


