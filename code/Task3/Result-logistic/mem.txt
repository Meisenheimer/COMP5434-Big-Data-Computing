Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    735.0 MiB    735.0 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    735.0 MiB      0.0 MiB           1       print("Loading data.")
   106    786.5 MiB     51.5 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    818.6 MiB     32.2 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    818.6 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    818.7 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    818.7 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    818.7 MiB      0.0 MiB           1       print("Training and testing.")
   117    818.7 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    818.7 MiB      0.0 MiB           1       model = getModel(args)
   120    865.2 MiB     46.6 MiB           1       model.fit(train_x, train_y)
   121    846.0 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    846.0 MiB      0.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    846.0 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    846.0 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    866.0 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    866.0 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    866.0 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    866.2 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    866.2 MiB      0.2 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    866.2 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    741.7 MiB    741.7 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    741.7 MiB      0.0 MiB           1       print("Loading data.")
   106    793.6 MiB     51.9 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    824.4 MiB     30.8 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    824.4 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    870.9 MiB     46.5 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    890.8 MiB     19.9 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    890.8 MiB      0.0 MiB           1       print("Training and testing.")
   117    890.8 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    890.8 MiB      0.0 MiB           1       model = getModel(args)
   120    937.4 MiB     46.6 MiB           1       model.fit(train_x, train_y)
   121    894.9 MiB    -42.5 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    895.0 MiB      0.1 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    895.0 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    895.0 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    914.9 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    914.9 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    914.9 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    915.1 MiB     -1.1 MiB       89934           for i in range(len(test_id)):
   133    915.1 MiB     -1.0 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    915.1 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    735.7 MiB    735.7 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    735.7 MiB      0.0 MiB           1       print("Loading data.")
   106    786.2 MiB     50.5 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    804.4 MiB     18.2 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    804.4 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    897.5 MiB     93.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    937.3 MiB     39.8 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    937.3 MiB      0.0 MiB           1       print("Training and testing.")
   117    937.3 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    937.3 MiB      0.0 MiB           1       model = getModel(args)
   120   1007.0 MiB     69.8 MiB           1       model.fit(train_x, train_y)
   121    941.3 MiB    -65.8 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    943.1 MiB      1.8 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    943.1 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    943.1 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    972.9 MiB     29.9 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    972.9 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    972.9 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    973.1 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    973.1 MiB      0.2 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    973.1 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    735.8 MiB    735.8 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    735.8 MiB      0.0 MiB           1       print("Loading data.")
   106    786.8 MiB     50.9 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    804.4 MiB     17.6 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    804.4 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    804.4 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    804.4 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    804.4 MiB      0.0 MiB           1       print("Training and testing.")
   117    804.4 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    804.4 MiB      0.0 MiB           1       model = getModel(args)
   120    851.0 MiB     46.6 MiB           1       model.fit(train_x, train_y)
   121    831.7 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    833.7 MiB      2.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    833.7 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    833.7 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    853.7 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    853.7 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    853.7 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    854.0 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    854.0 MiB      0.3 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    854.0 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    735.6 MiB    735.6 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    735.6 MiB      0.0 MiB           1       print("Loading data.")
   106    786.6 MiB     51.0 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    804.2 MiB     17.6 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    804.2 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    804.2 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    804.2 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    804.2 MiB      0.0 MiB           1       print("Training and testing.")
   117    804.2 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    804.2 MiB      0.0 MiB           1       model = getModel(args)
   120    850.8 MiB     46.6 MiB           1       model.fit(train_x, train_y)
   121    831.5 MiB    -19.2 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    833.5 MiB      2.0 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    833.5 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    833.5 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    853.5 MiB     20.0 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    853.5 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    853.5 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    853.8 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    853.8 MiB      0.2 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    853.8 MiB      0.0 MiB           1       return None


Filename: D:\Workspace\Projects\COMP5434-Big-Data-Computing\code\Task3\main.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    735.8 MiB    735.8 MiB           1   @profile(stream=open("./Result/mem.txt", "a", encoding="UTF-8"))
   103                                         def test(args: argparse.Namespace):
   104                                             # load the data from csv file.
   105    735.8 MiB      0.0 MiB           1       print("Loading data.")
   106    775.3 MiB     39.5 MiB           1       train_x, train_y, _ = loadData(os.path.join(args.data_dir, "train.csv"), args.feat_selection, True)
   107    786.7 MiB     11.4 MiB           1       test_x, test_id = loadData(os.path.join(args.data_dir, "test.csv"), args.feat_selection, False)
   108                                         
   109                                             # Preprocessing
   110    786.7 MiB      0.0 MiB           1       print("Preprocessing")
   111                                         
   112    786.7 MiB      0.0 MiB           1       train_x, train_y = preprocess(train_x, train_y, args, False)
   113    786.7 MiB      0.0 MiB           1       test_x = preprocess(test_x, np.zeros_like((test_x.shape[0])), args, True)
   114                                         
   115                                             # Training and testing.
   116    786.7 MiB      0.0 MiB           1       print("Training and testing.")
   117    786.7 MiB      0.0 MiB           1       score = 0.0
   118                                         
   119    786.7 MiB      0.0 MiB           1       model = getModel(args)
   120    820.6 MiB     33.8 MiB           1       model.fit(train_x, train_y)
   121    807.7 MiB    -12.9 MiB           1       pred_y = model.predict(train_x)
   122                                         
   123    810.6 MiB      2.9 MiB           1       score = f1_score(train_y, pred_y, average="macro")
   124                                         
   125    810.6 MiB      0.0 MiB           1       print("Train Score = %f." % score, file=args.log)
   126    810.6 MiB      0.0 MiB           1       print("Train Score = %f." % score)
   127                                         
   128    825.1 MiB     14.5 MiB           1       pred_y = model.predict(test_x)
   129                                         
   130    825.1 MiB      0.0 MiB           1       with open(os.path.join(args.output_dir, "res.csv"), "w") as fp:
   131    825.1 MiB      0.0 MiB           1           print("id,label", file=fp)
   132    825.3 MiB      0.0 MiB       89934           for i in range(len(test_id)):
   133    825.3 MiB      0.3 MiB       89933               print(f"{test_id[i]},{int(pred_y[i])}", file=fp)
   134                                         
   135    825.3 MiB      0.0 MiB           1       return None


